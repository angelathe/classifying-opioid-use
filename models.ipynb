{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import preprocessing\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from identification import vif_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in Data ###\n",
    "data = pd.read_csv(\"data_cleaning/final_data.csv\")\n",
    "\n",
    "\n",
    "vars = [\"REGION_YEAR\",\"AGELAST\",\"SEX\",\"RACETHX\",\"MARRY_YEARX\",\"EDUCYR\",\n",
    "\"BORNUSA\",\"FOODST_YEAR\",\"TTLP_YEARX\",\"FAMINC_YEAR\",\"POVCAT_YEAR\",\"POVLEV_YEAR\",\"WAGEP_YEARX\",\n",
    "\"DIVDP_YEARX\",\"SALEP_YEARX\",\"PENSP_YEARX\",\"PUBP_YEARX\",\"ADHDADDX\",\"ACTDTY\",\n",
    "'UNINSURED_ONLY', 'PRIVATE_ONLY', 'MEDICAID_ONLY', 'MEDICARE_ANY', 'MEDICARE_ADV', 'MEDICARE_MEDICAID', 'MEDICARE_PRIVATE',\t\n",
    "\"RTHLTH\",\"MNHLTH\",\"EMPST\",\"non_opioid_prescriptions\",\"NUM_CONDITIONS\",\"INJURY\"]\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "### Run identification ###\n",
    "y = pd.DataFrame(data, columns=['opioid_prescribed_at_all'])\n",
    "exog = pd.DataFrame(data, columns=vars)\n",
    "exog_vars = vif_detection(data,exog, y)\n",
    "\n",
    "### Data Normalization and Splitting ###\n",
    "X=pd.DataFrame(exog_vars).to_numpy()\n",
    "y=pd.DataFrame(y).to_numpy().reshape(len(y),)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_train, X_test_valid, y_train, y_test_valid = train_test_split(X_scaled, y, random_state=42, test_size = 0.2)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, random_state=42, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic model accuracy on valid: 82.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eujeneyum/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "### Model 1-Logistic Regression ###\n",
    "log_reg= LogisticRegression(max_iter = 1000).fit(X_train, y_train)  # apply scaling on training data\n",
    "score = log_reg.score(X_valid, y_valid)\n",
    "print(f\"logistic model accuracy on valid: {score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree accuracy on valid: 73.6%\n"
     ]
    }
   ],
   "source": [
    "### Model 2-Decision Tree ###\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree = decision_tree.fit(X_train, y_train)\n",
    "score = decision_tree.score(X_valid, y_valid)\n",
    "print(f\"tree accuracy on valid: {score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest with 10 estimators' accuracy on valid: 83.3%\n",
      "random forest with 50 estimators' accuracy on valid: 83.3%\n",
      "random forest with 100 estimators' accuracy on valid: 83.3%\n",
      "random forest with 250 estimators' accuracy on valid: 83.3%\n",
      "random forest with 500 estimators' accuracy on valid: 83.3%\n"
     ]
    }
   ],
   "source": [
    "### Model 3-Random Forest ###\n",
    "random_forest_scores = []\n",
    "for estimator in [10,50,100,250,500]:\n",
    "    forest_model = RandomForestClassifier(random_state = 0, n_jobs = 1, n_estimators = 100, class_weight = 'balanced')\n",
    "    forest_model = forest_model.fit(X_train, y_train)\n",
    "    score = forest_model.score(X_valid, y_valid)\n",
    "    random_forest_scores.append(score)\n",
    "    print(f\"random forest with {estimator} estimators' accuracy on valid: {score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'active_fun' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8g/3jp0k1x54d1f91mld1sc5gq80000gn/T/ipykernel_84856/598551524.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtype_of_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         clf = MLPClassifier(hidden_layer_sizes = layers,\n\u001b[0;32m---> 10\u001b[0;31m                                             \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_fun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                                             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                             \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'active_fun' is not defined"
     ]
    }
   ],
   "source": [
    "### Model 4-Neural Net ###\n",
    "nn_scores = []\n",
    "for layers in [(100,50,25), (10, 5, 2), (25, 25, 25), (10, 9, 8), (10, 5), (100, 25)]:\n",
    "    for active_func in ['relu', 'tanh', 'logistic']:\n",
    "        for alpha_val in [0.0001, 0.001, .01]:\n",
    "            for max_iterations in [100, 200, 500]:\n",
    "                for type_of_solver in ['sgd', 'adam']:\n",
    "                    if type_of_solver == 'sgd':\n",
    "                        clf = MLPClassifier(hidden_layer_sizes = layers,\n",
    "                                            activation = active_fun,\n",
    "                                            alpha = alpha_val,\n",
    "                                            solver = type_of_solver,\n",
    "                                            learning_rate = 'adaptive',\n",
    "                                            max_iter = max_iterations,\n",
    "                                            shuffle = True,\n",
    "                                            random_state=1).fit(X_train, y_train)\n",
    "                    if type_of_solver == 'adam':\n",
    "                        clf = MLPClassifier(hidden_layer_sizes = layers,\n",
    "                                            activation = active_fun,\n",
    "                                            alpha = alpha_val,\n",
    "                                            solver = type_of_solver,\n",
    "                                            max_iter = max_iterations,\n",
    "                                            shuffle = True,\n",
    "                                            random_state=1).fit(X_train, y_train)\n",
    "                    score = clf.score(X_valid, y_valid)\n",
    "                    nn_scores.append(score)\n",
    "                    print(f\"neural net with {layers} layers, {active_func} activation,\\\n",
    "                        {alpha_val} alpha, {max_iterations} max iternations, and \\\n",
    "                        {type_of_solver} type of solver accuracy on valid: {score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 5-Ada Boost ###\n",
    "ada_boost_scores = []\n",
    "for learning_rate in [0.01, .05, 0.1, 0.2]:\n",
    "    for n in [100, 200, 500, 1000]:\n",
    "        ada_boost = AdaBoostClassifier(n_estimators=n, learning_rate=learning_rate, algorithm='SAMME.R', random_state=1).fit(X_train, y_train)\n",
    "        score = ada_boost.score(X_valid, y_valid)\n",
    "        ada_boost_scores.append(score)\n",
    "        print(f\"Ada accuracy with learning rate of {learning_rate} and number estimators {n} on valid: {score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
